#! /usr/bin/env python
#
#   Examples of private data downloads
# 
#   all the things that can go wrong in astroquery ALMA (for private data?)
#
#   tested with astroquery-0.3.10.dev5282-py3.7.egg on April 18,2019
#
#
#   sometimes you see:
#        RuntimeError: No recommended backend was available. Install a recommended 3rd party backend package; or, install the keyrings.alt package if you want to use the non-recommended backends. See https://pypi.org/project/keyring for details.
#   just ignore, and try again (maybe few times), eventually it will magically work...
#
#   may need to 'pip install keyrings.alt' if it persists.
#
#   However, below there are some errors that I can't seem to resolve (bugs in AQ ?)
#
#   Info:   This SMC project has 15 fields (Tile*), in 7 by 15 fields.
#
import os, sys, re
import numpy as np
from astroquery.alma import Alma

pid = '2018.1.01115.S'
usr = 'kjameson'
ids = None

if len(sys.argv) > 1: pid = sys.argv[1]
if len(sys.argv) > 2: usr = sys.argv[2]
if len(sys.argv) > 3: ids = int(sys.argv[3])


pwd = os.getcwd() + '/data'
os.system('mkdir -p %s' % pwd)

alma = Alma()
alma.login(usr,store_password=True)
alma.cache_location = pwd
data = alma.query(payload={'project_code':pid},public=False,science=True)
uids = np.unique(data['Member ous id'])
print("For project code %s found:" % pid)
print(uids)
if ids != None:
    print("Only using %s" % uids[ids])
    uids = [uids[ids]]
nuids = len(uids)


if True:
    r1=re.compile('.*_of_.*tar$')
    # somehow only the first time in this loop it works, after
    # requests.exceptions.HTTPError: 500 Server Error: 500 for url: https://almascience.nrao.edu/rh/error?errorMessage=java.lang.IllegalArgumentException%3A+Invalid+UUID+string%3A+kjameson

    for uid in uids:
        print("Staging %s" % uid)
        link_list = alma.stage_data(uid)            # <-- fails on 2nd attempt
        url = link_list['URL']
        url1 = [x for x in url if r1.match(x)]
        print("Working on %s" % str(url1))
        alma.download_files(url1)

if False:
    r1=re.compile('.*_of_.*tar$')
    for i in range(nuids):
        data = alma.query(payload={'project_code':pid},public=False,science=True)
        uids = np.unique(data['Member ous id'])
        print("Staging %s" % uids[i])
        link_list = alma.stage_data(uids[i])        # <-- fails for 2nd attempt
        url = link_list['URL']
        url1 = [x for x in url if r1.match(x)]
        print("Working on %s" % str(url1))
        alma.download_files(url1)
        

if False:
    link_list = alma.stage_data(uids[0])
    # filelist = alma.download_and_extract_files(link_list['URL'], regex='.*fits*tar*')
    filelist = alma.download_and_extract_files(link_list['URL'], regex='.*_of_.*tar$')
    # -> ValueError: URLs should be links to tarballs. I found ...README.txt
    # alma.download_files(link_list['URL'][0])
    # -> MissingSchema: Invalid URL 'h': No schema supplied. Perhaps you meant http://h?
    url = link_list['URL']
    r1=re.compile('.*_of_.*tar$')              # e.g. 2018.1.01115.S_uid___A001_X133f_X196_001_of_001.tar
    url1 = [x for x in url if r1.match(x)]

if False:
    # this seems to take "forever" - the web interface is also slow (hours and hours) so perhaps this is also AQ
    link_list = alma.stage_data(uids)
    print(link_list['size'].sum())
    alma.download_files(link_list, cache=True)    
    
# ALL
# alma.download_files(link_list, cache=True)
# -> TypeError: unhashable type: 'Row'

# ONE
# alma.retrieve_data_from_uid(uids[0])
# -> will also get the asdm

#  Katherine Jameson: Request #1647986756662

# raise ValueError("URLs should be links to tarballs.")
